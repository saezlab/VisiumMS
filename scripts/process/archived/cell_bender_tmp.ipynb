{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recompute:  True\n",
      "raw_location:  /home/philipp/Work/VisiumMS/scripts/process/../../data/raw_old_sn\n",
      "filtered_location:  /home/philipp/Work/VisiumMS/scripts/process/../../data/raw/visium\n",
      "output_dir:  /home/philipp/Work/VisiumMS/scripts/process/../../data/cellbender_out\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from subprocess import Popen, STDOUT\n",
    "import scanpy as sc\n",
    "\n",
    "# harcoded configs\n",
    "recompute = True\n",
    "\n",
    "current_folder = globals()['_dh'][0] # for jupyter notebook\n",
    "#current_folder = Path(__file__).parent\n",
    "raw_location = current_folder / \"..\" / \"..\" / \"data\" / \"raw_old_sn\"\n",
    "filtered_location = current_folder / \"..\" / \"..\" / \"data\" / \"raw\" / \"visium\"\n",
    "output_dir = current_folder / \"..\" / \"..\" / \"data\" / \"cellbender_out\"\n",
    "\n",
    "# verbose, helpful for debugging\n",
    "print(\"recompute: \", recompute)\n",
    "print(\"raw_location: \", raw_location)\n",
    "print(\"filtered_location: \", filtered_location)\n",
    "print(\"output_dir: \", output_dir)\n",
    "\n",
    "samples = [sample for sample in os.listdir(raw_location) if not sample.startswith(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MS411'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = samples[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/philipp/Work/VisiumMS/scripts/process/../../data/cellbender_out/MS411\n"
     ]
    }
   ],
   "source": [
    "output_dir_sample = output_dir / sample\n",
    "output_dir_sample.mkdir(parents=True, exist_ok=True)\n",
    "print(output_dir_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/miniconda3/envs/torch_env2/lib/python3.9/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2826"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Here using as expected cell number the filtered barcode matrix\n",
    "filtered_adata = sc.read_10x_h5(filtered_location / sample / \"outs\" / \"filtered_feature_bc_matrix.h5\")\n",
    "expected_cells = filtered_adata.n_obs\n",
    "del filtered_adata\n",
    "expected_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/philipp/Work/VisiumMS/scripts/process/../../data/raw_old_sn/MS411/raw_feature_bc_matrix.h5\n"
     ]
    }
   ],
   "source": [
    "input_h5 = raw_location / sample / \"raw_feature_bc_matrix.h5\"\n",
    "print(input_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/miniconda3/envs/torch_env2/lib/python3.9/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "test = sc.read_10x_h5(input_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellbender:remove-background: Command:\n",
      "cellbender remove-background --input /home/philipp/Work/VisiumMS/scripts/process/../../data/raw_old_sn/MS411/raw_feature_bc_matrix.h5 --output cell_bender_matrix.h5 --model full --cuda --expected-cells 2826 --total-droplets-included 25000 --fpr 0.01 --epochs 150 --posterior-batch-size 5 --cells-posterior-reg-calc 50\n",
      "cellbender:remove-background: 2023-05-30 12:45:35\n",
      "cellbender:remove-background: Running remove-background\n",
      "cellbender:remove-background: Loading data from file /home/philipp/Work/VisiumMS/scripts/process/../../data/raw_old_sn/MS411/raw_feature_bc_matrix.h5\n",
      "cellbender:remove-background: CellRanger v3 format\n",
      "cellbender:remove-background: Trimming dataset for inference.\n",
      "cellbender:remove-background: Including 30689 genes that have nonzero counts.\n",
      "/home/philipp/Work/CellBender/cellbender/remove_background/data/dataset.py:1436: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  empty_log_counts = mode(np.round(np.log1p(counts[counts > cut]),\n",
      "cellbender:remove-background: Prior on counts in empty droplets is 120\n",
      "cellbender:remove-background: Prior on counts for cells is 7498\n",
      "cellbender:remove-background: Excluding barcodes with counts below 60\n",
      "cellbender:remove-background: Using 2826 probable cell barcodes, plus an additional 22174 barcodes, and 43929 empty droplets.\n",
      "cellbender:remove-background: Largest surely-empty droplet has 137 UMI counts.\n",
      "cellbender:remove-background: Running inference...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/philipp/Work/VisiumMS/scripts/process/cell_bencer_tmp.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/VisiumMS/scripts/process/cell_bencer_tmp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m p \u001b[39m=\u001b[39m Popen([\u001b[39m\"\u001b[39m\u001b[39mcellbender\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mremove-background\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/VisiumMS/scripts/process/cell_bencer_tmp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m--input\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(input_h5), \u001b[39m# input file\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/VisiumMS/scripts/process/cell_bencer_tmp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m--output\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcell_bender_matrix.h5\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/VisiumMS/scripts/process/cell_bencer_tmp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     cwd\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(output_dir_sample),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/VisiumMS/scripts/process/cell_bencer_tmp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     stderr\u001b[39m=\u001b[39mSTDOUT)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/VisiumMS/scripts/process/cell_bencer_tmp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m p\u001b[39m.\u001b[39;49mwait(timeout\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env2/lib/python3.9/subprocess.py:1189\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     endtime \u001b[39m=\u001b[39m _time() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m   1188\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[39m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m     \u001b[39m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     \u001b[39m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env2/lib/python3.9/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1917\u001b[0m (pid, sts) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_wait(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1918\u001b[0m \u001b[39m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m \u001b[39m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m \u001b[39m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[39mif\u001b[39;00m pid \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env2/lib/python3.9/subprocess.py:1875\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1874\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1875\u001b[0m     (pid, sts) \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mwaitpid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpid, wait_flags)\n\u001b[1;32m   1876\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1877\u001b[0m     \u001b[39m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m     \u001b[39m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1879\u001b[0m     \u001b[39m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m     pid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellbender:remove-background: [epoch 001]  average training loss: 2872.6945\n",
      "cellbender:remove-background: [epoch 002]  average training loss: 2382.3919  (17.5 seconds per epoch)\n",
      "cellbender:remove-background: [epoch 003]  average training loss: 2276.4157\n",
      "cellbender:remove-background: [epoch 004]  average training loss: 2224.0942\n",
      "cellbender:remove-background: [epoch 005]  average training loss: 2205.7675\n",
      "cellbender:remove-background: [epoch 005] average test loss: 2160.3754\n",
      "cellbender:remove-background: [epoch 006]  average training loss: 2186.7893\n",
      "cellbender:remove-background: [epoch 007]  average training loss: 2172.8793\n",
      "cellbender:remove-background: [epoch 008]  average training loss: 2160.5785\n",
      "cellbender:remove-background: [epoch 009]  average training loss: 2159.7639\n",
      "cellbender:remove-background: [epoch 010]  average training loss: 2153.3295\n",
      "cellbender:remove-background: [epoch 010] average test loss: 2124.8041\n",
      "cellbender:remove-background: [epoch 011]  average training loss: 2144.0043\n",
      "cellbender:remove-background: [epoch 012]  average training loss: 2147.3076\n",
      "cellbender:remove-background: [epoch 013]  average training loss: 2136.8359\n",
      "cellbender:remove-background: [epoch 014]  average training loss: 2129.5497\n",
      "cellbender:remove-background: [epoch 015]  average training loss: 2083.1272\n",
      "cellbender:remove-background: [epoch 015] average test loss: 2028.1879\n",
      "cellbender:remove-background: [epoch 016]  average training loss: 2054.6114\n",
      "cellbender:remove-background: [epoch 017]  average training loss: 2047.6634\n",
      "cellbender:remove-background: [epoch 018]  average training loss: 2040.0416\n",
      "cellbender:remove-background: [epoch 019]  average training loss: 2033.8700\n",
      "cellbender:remove-background: [epoch 020]  average training loss: 2022.4012\n",
      "cellbender:remove-background: [epoch 020] average test loss: 1987.2995\n",
      "cellbender:remove-background: [epoch 021]  average training loss: 2011.4453\n",
      "cellbender:remove-background: [epoch 022]  average training loss: 2008.5771\n",
      "cellbender:remove-background: [epoch 023]  average training loss: 2000.9077\n",
      "cellbender:remove-background: [epoch 024]  average training loss: 1994.3872\n",
      "cellbender:remove-background: [epoch 025]  average training loss: 1986.6418\n",
      "cellbender:remove-background: [epoch 025] average test loss: 1954.3261\n",
      "cellbender:remove-background: [epoch 026]  average training loss: 1979.6697\n",
      "cellbender:remove-background: [epoch 027]  average training loss: 1969.4791\n",
      "cellbender:remove-background: [epoch 028]  average training loss: 1957.5867\n",
      "cellbender:remove-background: [epoch 029]  average training loss: 1949.4087\n",
      "cellbender:remove-background: [epoch 030]  average training loss: 1944.2975\n",
      "cellbender:remove-background: [epoch 030] average test loss: 1918.4100\n",
      "cellbender:remove-background: [epoch 031]  average training loss: 1941.6213\n",
      "cellbender:remove-background: [epoch 032]  average training loss: 1939.6376\n",
      "cellbender:remove-background: [epoch 033]  average training loss: 1935.5483\n",
      "cellbender:remove-background: [epoch 034]  average training loss: 1930.9420\n",
      "cellbender:remove-background: [epoch 035]  average training loss: 1930.2262\n",
      "cellbender:remove-background: [epoch 035] average test loss: 1903.8442\n",
      "cellbender:remove-background: [epoch 036]  average training loss: 1928.5049\n",
      "cellbender:remove-background: [epoch 037]  average training loss: 1928.0203\n",
      "cellbender:remove-background: [epoch 038]  average training loss: 1925.9458\n",
      "cellbender:remove-background: [epoch 039]  average training loss: 1921.2914\n",
      "cellbender:remove-background: [epoch 040]  average training loss: 1919.2770\n",
      "cellbender:remove-background: [epoch 040] average test loss: 1902.9389\n",
      "cellbender:remove-background: [epoch 041]  average training loss: 1915.6648\n",
      "cellbender:remove-background: [epoch 042]  average training loss: 1918.2149\n",
      "cellbender:remove-background: [epoch 043]  average training loss: 1916.8061\n",
      "cellbender:remove-background: [epoch 044]  average training loss: 1916.1695\n",
      "cellbender:remove-background: [epoch 045]  average training loss: 1913.8314\n",
      "cellbender:remove-background: [epoch 045] average test loss: 1893.9402\n",
      "cellbender:remove-background: [epoch 046]  average training loss: 1910.8490\n",
      "cellbender:remove-background: [epoch 047]  average training loss: 1910.4898\n",
      "cellbender:remove-background: [epoch 048]  average training loss: 1908.6954\n",
      "cellbender:remove-background: [epoch 049]  average training loss: 1908.1364\n",
      "cellbender:remove-background: [epoch 050]  average training loss: 1904.1666\n",
      "cellbender:remove-background: [epoch 050] average test loss: 1893.2973\n",
      "cellbender:remove-background: [epoch 051]  average training loss: 1906.5181\n",
      "cellbender:remove-background: [epoch 052]  average training loss: 1903.7970\n",
      "cellbender:remove-background: [epoch 053]  average training loss: 1901.0329\n",
      "cellbender:remove-background: [epoch 054]  average training loss: 1899.5133\n",
      "cellbender:remove-background: [epoch 055]  average training loss: 1900.5140\n",
      "cellbender:remove-background: [epoch 055] average test loss: 1886.7975\n",
      "cellbender:remove-background: [epoch 056]  average training loss: 1899.6836\n",
      "cellbender:remove-background: [epoch 057]  average training loss: 1898.9372\n",
      "cellbender:remove-background: [epoch 058]  average training loss: 1899.5790\n",
      "cellbender:remove-background: [epoch 059]  average training loss: 1897.6432\n",
      "cellbender:remove-background: [epoch 060]  average training loss: 1895.7480\n",
      "cellbender:remove-background: [epoch 060] average test loss: 1875.6603\n",
      "cellbender:remove-background: [epoch 061]  average training loss: 1895.5725\n",
      "cellbender:remove-background: [epoch 062]  average training loss: 1894.3721\n",
      "cellbender:remove-background: [epoch 063]  average training loss: 1894.6545\n",
      "cellbender:remove-background: [epoch 064]  average training loss: 1894.0933\n",
      "cellbender:remove-background: [epoch 065]  average training loss: 1892.9573\n",
      "cellbender:remove-background: [epoch 065] average test loss: 1877.4707\n",
      "cellbender:remove-background: [epoch 066]  average training loss: 1892.4591\n",
      "cellbender:remove-background: [epoch 067]  average training loss: 1891.9526\n",
      "cellbender:remove-background: [epoch 068]  average training loss: 1892.0773\n",
      "cellbender:remove-background: [epoch 069]  average training loss: 1889.5104\n",
      "cellbender:remove-background: [epoch 070]  average training loss: 1889.8598\n",
      "cellbender:remove-background: [epoch 070] average test loss: 1870.7783\n",
      "cellbender:remove-background: [epoch 071]  average training loss: 1888.6114\n",
      "cellbender:remove-background: [epoch 072]  average training loss: 1888.0899\n",
      "cellbender:remove-background: [epoch 073]  average training loss: 1888.1451\n",
      "cellbender:remove-background: [epoch 074]  average training loss: 1887.9629\n",
      "cellbender:remove-background: [epoch 075]  average training loss: 1887.1836\n",
      "cellbender:remove-background: [epoch 075] average test loss: 1870.4653\n",
      "cellbender:remove-background: [epoch 076]  average training loss: 1886.6454\n",
      "cellbender:remove-background: [epoch 077]  average training loss: 1885.1440\n",
      "cellbender:remove-background: [epoch 078]  average training loss: 1885.2029\n",
      "cellbender:remove-background: [epoch 079]  average training loss: 1885.0087\n"
     ]
    }
   ],
   "source": [
    "p = Popen([\"cellbender\", \"remove-background\", \n",
    "    \"--input\", str(input_h5), # input file\n",
    "    \"--output\", \"cell_bender_matrix.h5\",\n",
    "    \"--model\", \"full\",\n",
    "    \"--cuda\", # cuda enables\n",
    "    \"--expected-cells\", str(expected_cells), # number of expected cells, no default\n",
    "    \"--total-droplets-included\", str(25000), # number of droplets from the rank-ordered UMI plot that will be analyzed, default 25_000\n",
    "    \"--fpr\", str(0.01), # target false positive rate, default 0.01\n",
    "    \"--epochs\", str(150), # how many epochs to train, default 150\n",
    "    \"--posterior-batch-size\",  str(5), # batch size for creating the posterior, default 20 (important if running of of GPU RAM)\n",
    "    \"--cells-posterior-reg-calc\", str(50)], # number of cells used to estimate posterior regularization lambda, default 100\n",
    "    cwd=str(output_dir_sample),\n",
    "    stderr=STDOUT)\n",
    "\n",
    "p.wait(timeout=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output_dir_sample = output_dir / sample\n",
    "output_dir_sample.mkdir(parents=True, exist_ok=True)\n",
    "print(output_dir_sample)\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Here using as expected cell number the filtered barcode matrix\n",
    "filtered_adata = sc.read_10x_h5(filtered_location / sample / \"outs\" / \"filtered_feature_bc_matrix.h5\")\n",
    "expected_cells = filtered_adata.n_obs\n",
    "del filtered_adata\n",
    "\n",
    "input_h5 = raw_location / sample / \"raw_feature_bc_matrix.h5\"\n",
    "print(input_h5)\n",
    "\n",
    "# create log file\n",
    "log_file = output_dir / sample / \"cell_bender_custom_log.txt\"\n",
    "with open(log_file, \"w\") as f:\n",
    "\n",
    "    f.write(\"input_h5: \" + str(input_h5) + \"\\n\")\n",
    "\n",
    "    f.write(\"output_dir_sample: \" + str(output_dir_sample) + \"\\n\")\n",
    "\n",
    "    p = Popen([\"cellbender\", \"remove-background\", \n",
    "        \"--input\", input_h5, # input file\n",
    "        \"--output\", \"cell_bender_matrix.h5\",\n",
    "        \"--model\", \"full\",\n",
    "        \"--cuda\", # cuda enables\n",
    "        \"--expected-cells\", str(expected_cells), # number of expected cells, no default\n",
    "        \"--total-droplets-included\", str(25000), # number of droplets from the rank-ordered UMI plot that will be analyzed, default 25_000\n",
    "        \"--fpr\", str(0.01), # target false positive rate, default 0.01\n",
    "        \"--epochs\", str(150), # how many epochs to train, default 150\n",
    "        \"--posterior-batch-size\",  str(5), # batch size for creating the posterior, default 20 (important if running of of GPU RAM)\n",
    "        \"--cells-posterior-reg-calc\", str(50)], # number of cells used to estimate posterior regularization lambda, default 100\n",
    "        cwd=output_dir_sample,\n",
    "        stderr=STDOUT,\n",
    "        stdout=f\n",
    "        )\n",
    "    \n",
    "    p.wait(timeout=None)    # https://docs.python.org/3/library/subprocess.html#subprocess.Popen.wait\n",
    "                            # don't spawn another process if p has not finished yet (sequential handling)\n",
    "\n",
    "# install cellbender: pip install -e .\n",
    "# call: python scripts/process/cell_bender.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
